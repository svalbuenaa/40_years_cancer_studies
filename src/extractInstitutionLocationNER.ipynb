{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b50906a7-9ad3-4ca3-a339-5376174f2884",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "import os\n",
    "import ast\n",
    "\n",
    "# Libraries for language detection. Avoid warnings\n",
    "from langdetect import detect, DetectorFactory\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module='langdetect')\n",
    "\n",
    "# Ensure consistent language detection results across runs\n",
    "DetectorFactory.seed = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e90a28d0-5b71-4e39-b033-de9759e5f8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LoadspaCy models\n",
    "\n",
    "nlp_models = {}\n",
    "nlp_models['en'] = spacy.load(\"en_core_web_lg\")\n",
    "nlp_models['es'] = spacy.load(\"es_core_news_lg\")\n",
    "nlp_models['fr'] = spacy.load(\"fr_core_news_lg\")\n",
    "nlp_models['de'] = spacy.load(\"de_core_news_lg\")\n",
    "nlp_models['it'] = spacy.load(\"it_core_news_lg\")\n",
    "nlp_models['ja'] = spacy.load(\"fr_core_news_lg\")\n",
    "nlp_models['pl'] = spacy.load(\"pl_core_news_lg\")\n",
    "nlp_models['pt'] = spacy.load(\"pt_core_news_lg\")\n",
    "nlp_models['ru'] = spacy.load(\"ru_core_news_lg\")\n",
    "nlp_models['sv'] = spacy.load(\"sv_core_news_lg\")\n",
    "nlp_models['undetermined'] = spacy.load(\"xx_ent_wiki_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74f0cca7-8ad5-4ec8-bcdf-b8f8ff8f480e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " C:\\Users\\svalb\\OneDrive\\Escritorio\\Data_40_years_cancer_studies\\parsedXMLs\\\n"
     ]
    }
   ],
   "source": [
    "# Input directory (dir. with csvs containing parsed articles)\n",
    "DF_input = input().strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe57bf8a-af59-48ce-8c9f-a404e5fc7d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_csvs = []\n",
    "\n",
    "for file in os.listdir(DF_input):\n",
    "    if file[-4:] == \".csv\":\n",
    "        list_csvs.append(file)\n",
    "\n",
    "n_csvs = len(list_csvs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba36d537-2f52-41e7-8672-9a291227df69",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax. Perhaps you forgot a comma? (3964633194.py, line 83)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 83\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mdf_save = df.save.drop(columns=[\"\"PMID_NER\"\"])\u001b[39m\n                                    ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax. Perhaps you forgot a comma?\n"
     ]
    }
   ],
   "source": [
    "# Extract the affiliation of the last author (or, if that is not available, of any author) of each article\n",
    "# Then, do NER on the affiliation, add result to dataframe and save it\n",
    "no_affiliation = []\n",
    "for csv in list_csvs[0:1]:\n",
    "    NER_input = {} # PMIDs used as keys, affiliation for this PMID as values\n",
    "    NER_lastAuthor = {} # PMIDs used as keys, NER of affiliation as values\n",
    "    df = pd.read_csv(os.path.join(DF_input + csv))\n",
    "    # Part 1: Extract affiliation of last (or, if not available, any other) author of each article\n",
    "    print(\"Extracting affiliation of articles in csv: \" + csv + \" (\" + str(list_csvs.index(csv)+1) + \"/\" + str(n_csvs) + \")\")\n",
    "    \n",
    "    for i in range(df.index[-1] + 1): # Iterate through all rows, including the last one\n",
    "        try:\n",
    "            authors_data = ast.literal_eval(df.iat[i, 6])\n",
    "            last_author = authors_data[-1]\n",
    "    \n",
    "            affiliation_found = False\n",
    "            if \"Affiliation\" in last_author and last_author[\"Affiliation\"]:\n",
    "                # If the last author has an \"Affiliation\" key and it's not empty,\n",
    "                # take the first one. You can modify this to take any specific one\n",
    "                # or iterate if you have a preference.\n",
    "                NER_input[df.iat[i,1].item()] = last_author[\"Affiliation\"][0]\n",
    "                affiliation_found = True\n",
    "            else:\n",
    "                # If the last author doesn't have an \"Affiliation\" key or it's empty,\n",
    "                # try to find any affiliation within their entry.\n",
    "                # This part assumes \"Affiliation\" is always a list of strings if present.\n",
    "                for key, value in last_author.items():\n",
    "                    if key == \"Affiliation\" and isinstance(value, list) and value:\n",
    "                        NER_input[df.iat[i,1].item()] = value[0] # Taking the first one found\n",
    "                        affiliation_found = True\n",
    "                        break # Stop after finding the first affiliation for this author\n",
    "    \n",
    "            if not affiliation_found:\n",
    "                NER_input[df.iat[i,1].item()] = None\n",
    "                no_affiliation.append(df.iat[i, 1])\n",
    "    \n",
    "        except (SyntaxError, ValueError, IndexError, KeyError):\n",
    "            # Handle cases where ast.literal_eval fails, or index is out of bounds,\n",
    "            # or 'Affiliation' key is not found in the expected structure.\n",
    "            NER_input[df.iat[i,1].item()] = None\n",
    "            no_affiliation.append(df.iat[i, 1])\n",
    "\n",
    "    # Part 2: Do NER on the affiliation to extract structured info\n",
    "    for article in list(NER_input.keys()):\n",
    "        # Default language in affiliation text\n",
    "        detected_lang = \"undetermined\"\n",
    "\n",
    "        # Attempt to detect affiliation text language\n",
    "        try:\n",
    "            detected_lang = detect(sentence)\n",
    "        except Exception as e:\n",
    "            continue\n",
    "\n",
    "        # Use the model for the detected language (or a multilingual model if language not detected or no model available for the detected language)\n",
    "        # Do NER with this model on the affiliation\n",
    "        try:\n",
    "            # Load model\n",
    "            nlp = nlp_models.get(detected_lang, nlp_models[\"undetermined\"])\n",
    "\n",
    "            # Load affiliation text, do NER\n",
    "            doc = nlp(NER_input[article])\n",
    "            sentence_entities = []\n",
    "\n",
    "            # Extract entities of interest\n",
    "            for ent in doc.ents:\n",
    "                if ent.label_ in [\"ORG\", \"LOC\", \"GPE\"]:\n",
    "                    sentence_entities.append({\"text\": ent.text, \"label\": ent.label_})\n",
    "\n",
    "            # Save the entities associated to the article DOI\n",
    "            NER_lastAuthor[article] = ({\"entities\": sentence_entities})\n",
    "\n",
    "        # If NER not possible, store an empty dict\n",
    "        except ValueError:\n",
    "            NER_lastAuthor[article] = {}\n",
    "\n",
    "    # Create df from dictionary\n",
    "    df_NER_lastAuthor = pd.DataFrame.from_dict(processed_NER_lastAuthor, orient=\"index\", columns=\"NER_lastAuthor\")\n",
    "    df_NER_lastAuthor.rename(columns={\"entities\": \"NER_lastAuthor\"})\n",
    "    df_NER_lastAuthor[\"PMID_NER\"] = df_NER_lastAuthor.index\n",
    "\n",
    "    # Merge with original df, save\n",
    "    df_save = pd.merge(df, df_NER_lastAuthor, left_on= \"PMID\", right_on=\"PMID_NER\", how=\"left\")\n",
    "    df_save = df.save.drop(columns=[\"PMID_NER\"])\n",
    "    df_save.to_csv(DF_input+csv, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c949a9f0-e526-4d2f-a1be-dcff1348fe5c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
