{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f61c5c6-24c1-429a-81d4-a3318249a6ca",
   "metadata": {},
   "source": [
    "### NOTE\n",
    "\n",
    "The use of GLiNER requires *sentencepiece*, which appears to be incompatible with Python 3.13 (the version used in this project). Therefore, a new environment with Python 3.10 was employed for NER using GLiNER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4939d00c-2f1e-492c-91bf-05fa0d1d6939",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a53deef7a27944e495e40a6f1c764b3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 197 files:   0%|          | 0/197 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\svalb\\anaconda3\\envs\\cancer_studies310\\lib\\site-packages\\transformers\\convert_slow_tokenizer.py:562: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from gliner import GLiNER\n",
    "import time\n",
    "model = GLiNER.from_pretrained(\"knowledgator/gliner-x-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ae73302-a24e-4d72-b676-7ed2df2e7dc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "    C:\\Users\\svalb\\OneDrive\\Escritorio\\Data_40_years_cancer_studies\\parsedXMLs\\\n"
     ]
    }
   ],
   "source": [
    "DF_input = input().strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8644dad7-37ef-4ab5-a266-2e787fb8c6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import list of csvs to parse\n",
    "list_csvs = []\n",
    "\n",
    "for file in os.listdir(DF_input):\n",
    "    if file[-4:] == \".csv\":\n",
    "        list_csvs.append(file)\n",
    "\n",
    "n_csvs = len(list_csvs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ff51b3b-d201-419f-b98a-165a346974c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['parsedX_100000.csv',\n",
       " 'parsedX_1000000.csv',\n",
       " 'parsedX_1100000.csv',\n",
       " 'parsedX_1200000.csv',\n",
       " 'parsedX_1300000.csv',\n",
       " 'parsedX_1400000.csv',\n",
       " 'parsedX_1500000.csv',\n",
       " 'parsedX_1600000.csv',\n",
       " 'parsedX_1700000.csv',\n",
       " 'parsedX_1800000.csv',\n",
       " 'parsedX_1900000.csv',\n",
       " 'parsedX_200000.csv',\n",
       " 'parsedX_2000000.csv',\n",
       " 'parsedX_2100000.csv',\n",
       " 'parsedX_2200000.csv',\n",
       " 'parsedX_2300000.csv',\n",
       " 'parsedX_2400000.csv',\n",
       " 'parsedX_2500000.csv',\n",
       " 'parsedX_2600000.csv',\n",
       " 'parsedX_2700000.csv',\n",
       " 'parsedX_2800000.csv',\n",
       " 'parsedX_2900000.csv',\n",
       " 'parsedX_300000.csv',\n",
       " 'parsedX_3000000.csv',\n",
       " 'parsedX_3100000.csv',\n",
       " 'parsedX_3200000.csv',\n",
       " 'parsedX_3300000.csv',\n",
       " 'parsedX_3400000.csv',\n",
       " 'parsedX_3500000.csv',\n",
       " 'parsedX_3600000.csv',\n",
       " 'parsedX_3700000.csv',\n",
       " 'parsedX_3800000.csv',\n",
       " 'parsedX_3900000.csv',\n",
       " 'parsedX_400000.csv',\n",
       " 'parsedX_4000000.csv',\n",
       " 'parsedX_4100000.csv',\n",
       " 'parsedX_4200000.csv',\n",
       " 'parsedX_4300000.csv',\n",
       " 'parsedX_4400000.csv',\n",
       " 'parsedX_4454000.csv',\n",
       " 'parsedX_500000.csv',\n",
       " 'parsedX_600000.csv',\n",
       " 'parsedX_700000.csv',\n",
       " 'parsedX_800000.csv',\n",
       " 'parsedX_900000.csv']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_csvs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bbb1c2c8-90da-43a7-97b3-e4b48b946cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractCancerAnimalGLiNER(cell_content):\n",
    "    # If NER extracted nothing, return None\n",
    "    if pd.isna(cell_content):\n",
    "        return None\n",
    "    else:\n",
    "        labels = [\"cancer type\", \"animal\", \"patient\"]\n",
    "        entities = model.predict_entities(cell_content, labels, threshold=0.5)\n",
    "        return entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bfb7b41-43c2-4f47-a89f-2809e0008aa3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing csv: parsedX_100000.csv, 1 / 45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    }
   ],
   "source": [
    "for csv in list_csvs:\n",
    "    start = time.time()\n",
    "    print(f\"Parsing csv: {csv}, {list_csvs.index(csv)+1} / {n_csvs}\")\n",
    "    df = pd.read_csv(DF_input + csv)\n",
    "    df[\"Cancer, species\"] = df[\"Abstract\"].apply(extractCancerAnimalGLiNER)\n",
    "    df.to_csv(DF_input)\n",
    "    del df\n",
    "    with open(DF_input + \"csv files with Cancer and Species from GLiNER.txt\", \"a\") as f:\n",
    "            f.write(csv+\"\\n\")\n",
    "    print(f\"--Parsing time: {round(time.time()-start, 2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6756b5-c248-489b-b3e0-4e08c8e94e54",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
