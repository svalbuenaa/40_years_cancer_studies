{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "46de7a9c-29ca-4940-9a60-3e8d926a9997",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import time\n",
    "import re\n",
    "import ast\n",
    "import country_converter as coco\n",
    "import time\n",
    "import requests\n",
    "import json\n",
    "import googlemaps\n",
    "import pandas as pd\n",
    "from urllib.parse import quote_plus\n",
    "from collections import Counter\n",
    "from functools import lru_cache\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Manage API Keys\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "user_agent_NOMINATIM = os.getenv(\"USER_AGENT_NOMINATIM\")\n",
    "\n",
    "import logging\n",
    "coco_logger = logging.getLogger('country_converter.country_converter')\n",
    "coco_logger.setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0510855-6c4d-479d-b77d-3d1bcc356c9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " D:\\Data_40_years_cancer_studies\\BERT_NER_parsedXMLs_temp_isna_notna_base\\\n"
     ]
    }
   ],
   "source": [
    "DF_isna_input = input().strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69005b9a-d637-40bd-b4e3-b4360325f507",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(DF_isna_input + \"BERT_NER_temp_isna_notna.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "349bd85a-48b1-4afc-8010-6a51035f9b6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " C:\\Users\\svalb\\OneDrive\\Escritorio\\Data_40_years_cancer_studies\\resources\\allCountries_clean.csv\n"
     ]
    }
   ],
   "source": [
    "# Path to the .csv file with geographical entities information \n",
    "entities_database_input = input().strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "627c7949-26cf-42d5-8df1-8dcc7cf27b03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " C:\\Users\\svalb\\OneDrive\\Escritorio\\Data_40_years_cancer_studies\\resources\\ScimagoIR 2025 - Overall Rank.csv\n"
     ]
    }
   ],
   "source": [
    "# Path to the .csv file with scientific institutions information\n",
    "institutions_database_input = input().strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b1f06086-4ee3-4dc8-8a1f-695ee19d5dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import databases\n",
    "entities_database = pd.read_csv(entities_database_input)\n",
    "institutions_database = pd.read_csv(institutions_database_input, sep=\";\")\n",
    "\n",
    "# Remove \" *\" from institutions when present\n",
    "institutions_database[\"Institution\"] = institutions_database[\"Institution\"].apply(lambda x: x[:-2] if x[-2:] == \" *\" else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "71a3bdc5-e871-4586-88c4-0ed920b58e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fixed = df.loc[df[\"Country\"].notna()]\n",
    "df_to_fix = df.loc[df[\"Country\"].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "08587211-347a-46d9-a2c0-5f0c3be80a55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PMID</th>\n",
       "      <th>Authors</th>\n",
       "      <th>NER_lastAuthor</th>\n",
       "      <th>Country</th>\n",
       "      <th>Country_source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28520365</td>\n",
       "      <td>[{'Name': 'Laura Dean', 'Affiliation': ['NCBI'...</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28520372</td>\n",
       "      <td>[{'Name': 'Laura Dean', 'Affiliation': ['NCBI'...</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28520376</td>\n",
       "      <td>[{'Name': 'Laura Dean', 'Affiliation': ['NCBI'...</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28520377</td>\n",
       "      <td>[{'Name': 'Laura Dean', 'Affiliation': ['NCBI'...</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28723017</td>\n",
       "      <td>[{'Name': 'Ari D. Leib', 'Affiliation': ['Aden...</td>\n",
       "      <td>[{'text': 'Farber Cancer Institute', 'label': ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141696</th>\n",
       "      <td>11265390</td>\n",
       "      <td>[{'Name': 'G Namysłowski', 'Affiliation': ['II...</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141697</th>\n",
       "      <td>11265404</td>\n",
       "      <td>[{'Name': 'J Takahashi', 'Affiliation': ['Dept...</td>\n",
       "      <td>[{'text': 'Radiation Oncology', 'label': 'ORG'}]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141698</th>\n",
       "      <td>11265406</td>\n",
       "      <td>[{'Name': 'H Terashima', 'Affiliation': ['Dept...</td>\n",
       "      <td>[{'text': 'Surgery, Hiraka General Hospital', ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141699</th>\n",
       "      <td>11265412</td>\n",
       "      <td>[{'Name': 'M Ishizaki', 'Affiliation': ['Dept....</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141700</th>\n",
       "      <td>11265414</td>\n",
       "      <td>[{'Name': 'H Tanaka', 'Affiliation': ['Dept. o...</td>\n",
       "      <td>[{'text': 'Obstetrics and Gynecology', 'label'...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>121561 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            PMID                                            Authors  \\\n",
       "0       28520365  [{'Name': 'Laura Dean', 'Affiliation': ['NCBI'...   \n",
       "1       28520372  [{'Name': 'Laura Dean', 'Affiliation': ['NCBI'...   \n",
       "2       28520376  [{'Name': 'Laura Dean', 'Affiliation': ['NCBI'...   \n",
       "3       28520377  [{'Name': 'Laura Dean', 'Affiliation': ['NCBI'...   \n",
       "4       28723017  [{'Name': 'Ari D. Leib', 'Affiliation': ['Aden...   \n",
       "...          ...                                                ...   \n",
       "141696  11265390  [{'Name': 'G Namysłowski', 'Affiliation': ['II...   \n",
       "141697  11265404  [{'Name': 'J Takahashi', 'Affiliation': ['Dept...   \n",
       "141698  11265406  [{'Name': 'H Terashima', 'Affiliation': ['Dept...   \n",
       "141699  11265412  [{'Name': 'M Ishizaki', 'Affiliation': ['Dept....   \n",
       "141700  11265414  [{'Name': 'H Tanaka', 'Affiliation': ['Dept. o...   \n",
       "\n",
       "                                           NER_lastAuthor Country  \\\n",
       "0                                                      []     NaN   \n",
       "1                                                      []     NaN   \n",
       "2                                                      []     NaN   \n",
       "3                                                      []     NaN   \n",
       "4       [{'text': 'Farber Cancer Institute', 'label': ...     NaN   \n",
       "...                                                   ...     ...   \n",
       "141696                                                 []     NaN   \n",
       "141697   [{'text': 'Radiation Oncology', 'label': 'ORG'}]     NaN   \n",
       "141698  [{'text': 'Surgery, Hiraka General Hospital', ...     NaN   \n",
       "141699                                                 []     NaN   \n",
       "141700  [{'text': 'Obstetrics and Gynecology', 'label'...     NaN   \n",
       "\n",
       "       Country_source  \n",
       "0                 NaN  \n",
       "1                 NaN  \n",
       "2                 NaN  \n",
       "3                 NaN  \n",
       "4                 NaN  \n",
       "...               ...  \n",
       "141696            NaN  \n",
       "141697            NaN  \n",
       "141698            NaN  \n",
       "141699            NaN  \n",
       "141700            NaN  \n",
       "\n",
       "[121561 rows x 5 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_to_fix[[\"PMID\", \"Authors\", \"NER_lastAuthor\", \"Country\", \"Country_source\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "55e6f178-03d2-4ad5-9972-22106947a9e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PMID</th>\n",
       "      <th>Authors</th>\n",
       "      <th>NER_BERT</th>\n",
       "      <th>Country</th>\n",
       "      <th>Country_source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28520365</td>\n",
       "      <td>[{'Name': 'Laura Dean', 'Affiliation': ['NCBI'...</td>\n",
       "      <td>[{'entity_group': 'INS', 'score': np.float32(0...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28520372</td>\n",
       "      <td>[{'Name': 'Laura Dean', 'Affiliation': ['NCBI'...</td>\n",
       "      <td>[{'entity_group': 'INS', 'score': np.float32(0...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28520376</td>\n",
       "      <td>[{'Name': 'Laura Dean', 'Affiliation': ['NCBI'...</td>\n",
       "      <td>[{'entity_group': 'INS', 'score': np.float32(0...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28520377</td>\n",
       "      <td>[{'Name': 'Laura Dean', 'Affiliation': ['NCBI'...</td>\n",
       "      <td>[{'entity_group': 'INS', 'score': np.float32(0...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28723017</td>\n",
       "      <td>[{'Name': 'Ari D. Leib', 'Affiliation': ['Aden...</td>\n",
       "      <td>[{'entity_group': 'INS', 'score': np.float32(0...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141696</th>\n",
       "      <td>11265390</td>\n",
       "      <td>[{'Name': 'G Namysłowski', 'Affiliation': ['II...</td>\n",
       "      <td>[{'entity_group': 'INS', 'score': np.float32(0...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141697</th>\n",
       "      <td>11265404</td>\n",
       "      <td>[{'Name': 'J Takahashi', 'Affiliation': ['Dept...</td>\n",
       "      <td>[{'entity_group': 'INS', 'score': np.float32(0...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141698</th>\n",
       "      <td>11265406</td>\n",
       "      <td>[{'Name': 'H Terashima', 'Affiliation': ['Dept...</td>\n",
       "      <td>[{'entity_group': 'INS', 'score': np.float32(0...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141699</th>\n",
       "      <td>11265412</td>\n",
       "      <td>[{'Name': 'M Ishizaki', 'Affiliation': ['Dept....</td>\n",
       "      <td>[{'entity_group': 'INS', 'score': np.float32(0...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141700</th>\n",
       "      <td>11265414</td>\n",
       "      <td>[{'Name': 'H Tanaka', 'Affiliation': ['Dept. o...</td>\n",
       "      <td>[{'entity_group': 'INS', 'score': np.float32(0...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>121561 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            PMID                                            Authors  \\\n",
       "0       28520365  [{'Name': 'Laura Dean', 'Affiliation': ['NCBI'...   \n",
       "1       28520372  [{'Name': 'Laura Dean', 'Affiliation': ['NCBI'...   \n",
       "2       28520376  [{'Name': 'Laura Dean', 'Affiliation': ['NCBI'...   \n",
       "3       28520377  [{'Name': 'Laura Dean', 'Affiliation': ['NCBI'...   \n",
       "4       28723017  [{'Name': 'Ari D. Leib', 'Affiliation': ['Aden...   \n",
       "...          ...                                                ...   \n",
       "141696  11265390  [{'Name': 'G Namysłowski', 'Affiliation': ['II...   \n",
       "141697  11265404  [{'Name': 'J Takahashi', 'Affiliation': ['Dept...   \n",
       "141698  11265406  [{'Name': 'H Terashima', 'Affiliation': ['Dept...   \n",
       "141699  11265412  [{'Name': 'M Ishizaki', 'Affiliation': ['Dept....   \n",
       "141700  11265414  [{'Name': 'H Tanaka', 'Affiliation': ['Dept. o...   \n",
       "\n",
       "                                                 NER_BERT Country  \\\n",
       "0       [{'entity_group': 'INS', 'score': np.float32(0...     NaN   \n",
       "1       [{'entity_group': 'INS', 'score': np.float32(0...     NaN   \n",
       "2       [{'entity_group': 'INS', 'score': np.float32(0...     NaN   \n",
       "3       [{'entity_group': 'INS', 'score': np.float32(0...     NaN   \n",
       "4       [{'entity_group': 'INS', 'score': np.float32(0...     NaN   \n",
       "...                                                   ...     ...   \n",
       "141696  [{'entity_group': 'INS', 'score': np.float32(0...     NaN   \n",
       "141697  [{'entity_group': 'INS', 'score': np.float32(0...     NaN   \n",
       "141698  [{'entity_group': 'INS', 'score': np.float32(0...     NaN   \n",
       "141699  [{'entity_group': 'INS', 'score': np.float32(0...     NaN   \n",
       "141700  [{'entity_group': 'INS', 'score': np.float32(0...     NaN   \n",
       "\n",
       "       Country_source  \n",
       "0                 NaN  \n",
       "1                 NaN  \n",
       "2                 NaN  \n",
       "3                 NaN  \n",
       "4                 NaN  \n",
       "...               ...  \n",
       "141696            NaN  \n",
       "141697            NaN  \n",
       "141698            NaN  \n",
       "141699            NaN  \n",
       "141700            NaN  \n",
       "\n",
       "[121561 rows x 5 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_to_fix[[\"PMID\", \"Authors\", \"NER_BERT\", \"Country\", \"Country_source\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6a8e986c-04e4-4b9f-bccb-e8d013869cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a dictionary for US states. \n",
    "# Many article's affiliation have the state name/ code and not \"United States\"\n",
    "us_states = [\n",
    "    \"Alabama\", \"AL\", \"Al\",\n",
    "    \"Alaska\", \"AK\", \"Ak\",\n",
    "    \"Arizona\", \"AZ\", \"Az\",\n",
    "    \"Arkansas\", \"AR\", \"Ar\",\n",
    "    \"California\", \"CA\", \"Ca\",\n",
    "    \"Colorado\", \"CO\", \"Co\",\n",
    "    \"Connecticut\", \"CT\", \"Ct\",\n",
    "    \"Delaware\", \"DE\", \"De\",\n",
    "    \"Florida\", \"FL\", \"Fl\",\n",
    "    \"Georgia\", \"GA\", \"Ga\",\n",
    "    \"Hawaii\", \"HI\", \"Hi\",\n",
    "    \"Idaho\", \"ID\", \"Id\",\n",
    "    \"Illinois\", \"IL\", \"Il\",\n",
    "    \"Indiana\", \"IN\", \"In\",\n",
    "    \"Iowa\", \"IA\", \"Ia\",\n",
    "    \"Kansas\", \"KS\", \"Ks\",\n",
    "    \"Kentucky\", \"KY\", \"Ky\",\n",
    "    \"Louisiana\", \"LA\", \"La\",\n",
    "    \"Maine\", \"ME\", \"Me\",\n",
    "    \"Maryland\", \"MD\", \"Md\",\n",
    "    \"Massachusetts\", \"MA\", \"Ma\",\n",
    "    \"Michigan\", \"MI\", \"Mi\",\n",
    "    \"Minnesota\", \"MN\", \"Mn\",\n",
    "    \"Mississippi\", \"MS\", \"Ms\",\n",
    "    \"Missouri\", \"MO\", \"Mo\",\n",
    "    \"Montana\", \"MT\", \"Mt\",\n",
    "    \"Nebraska\", \"NE\", \"Ne\",\n",
    "    \"Nevada\", \"NV\", \"Nv\",\n",
    "    \"New Hampshire\", \"NH\", \"Nh\",\n",
    "    \"New Jersey\", \"NJ\", \"Nj\",\n",
    "    \"New Mexico\", \"NM\", \"Nm\",\n",
    "    \"New York\", \"NY\", \"Ny\",\n",
    "    \"North Carolina\", \"NC\", \"Nc\",\n",
    "    \"North Dakota\", \"ND\", \"Nd\",\n",
    "    \"Ohio\", \"OH\", \"Oh\",\n",
    "    \"Oklahoma\", \"OK\", \"Ok\",\n",
    "    \"Oregon\", \"OR\", \"Or\",\n",
    "    \"Pennsylvania\", \"PA\", \"Pa\",\n",
    "    \"Rhode Island\", \"RI\", \"Ri\",\n",
    "    \"South Carolina\", \"SC\", \"Sc\",\n",
    "    \"South Dakota\", \"SD\", \"Sd\",\n",
    "    \"Tennessee\", \"TN\", \"Tn\",\n",
    "    \"Texas\", \"TX\", \"Tx\",\n",
    "    \"Utah\", \"UT\", \"Ut\",\n",
    "    \"Vermont\", \"VT\", \"Vt\",\n",
    "    \"Virginia\", \"VA\", \"Va\",\n",
    "    \"Washington\", \"WA\", \"Wa\",\n",
    "    \"West Virginia\", \"WV\", \"Wv\",\n",
    "    \"Wisconsin\", \"WI\", \"Wi\",\n",
    "    \"Wyoming\", \"WY\", \"Wy\",\n",
    "    \"District of Columbia\", \"DC\", \"Dc\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a859b3b1-a591-4095-b80b-f57d9ee8b36c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precompute lookup tables\n",
    "institution_to_country = dict(zip(institutions_database[\"Institution\"], institutions_database[\"Country\"]))\n",
    "entity_to_country = dict(zip(entities_database[\"name\"], entities_database[\"country code\"]))\n",
    "all_institutions_set = set(institution_to_country.keys())\n",
    "\n",
    "# Instance conerter\n",
    "cc = coco.CountryConverter()\n",
    "\n",
    "# MUST include contact info. Example format: 'Application_name/1.0 (yourEmail@provider.com)'\n",
    "headers = {\n",
    "    'User-Agent': user_agent_NOMINATIM  \n",
    "}\n",
    "\n",
    "# Compiled regex list if regex matching is required\n",
    "compiled_institution_patterns = [(inst, re.compile(re.escape(inst))) for inst in institution_to_country]\n",
    "\n",
    "@lru_cache(maxsize=1000)\n",
    "def get_country_from_text(text):\n",
    "    \"\"\"Fast country name conversion with cache.\"\"\"\n",
    "    try:\n",
    "        # Attempt to extract country directly from text passed to the function (NER)\n",
    "        result = cc.convert(names=text, to='name_short')\n",
    "        return result if result != \"not found\" else None\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def extract_country_with_states(cell_content):\n",
    "    # If NER extracted nothing, return None\n",
    "    if pd.isna(cell_content):\n",
    "        return None, None\n",
    "\n",
    "    try:\n",
    "        # Try to convert the content in the NER field to list\n",
    "        ## First, clean it from np function names\n",
    "        cell_content = re.sub(r'np\\.float32\\(([^)]+)\\)', r'\\1', cell_content)\n",
    "        \n",
    "        parsed_content = ast.literal_eval(cell_content)\n",
    "        # Make a separate variable for the organizations\n",
    "        parsed_content_ins = [ins for ins in parsed_content if ins[\"entity_group\"] == \"INS\"]\n",
    "    except:\n",
    "        return None, None\n",
    "\n",
    "    # If output is not a list, return None\n",
    "    if not isinstance(parsed_content, list):\n",
    "        return None, None\n",
    "\n",
    "    countries = []\n",
    "    text_blob = []\n",
    "\n",
    "    # NER field should contain several dictionaries (one per entity found by NER)\n",
    "    for el in parsed_content:\n",
    "        if isinstance(el, dict):\n",
    "            # Separate text and label (INS, SUBC, COU, etc.)\n",
    "            text = el.get(\"word\", \"\").strip(\".\") # Remove points as trailing spaces after/before texts\n",
    "            label = el.get(\"entity_group\", \"\")\n",
    "\n",
    "            # At some point passing the whole string to an API might be needed, so they are prepared\n",
    "            text_blob.append(text)\n",
    "\n",
    "            # Check if any named entity corresponds to a US state. If so, return United States\n",
    "            if text in us_states:\n",
    "                return \"United States\", \"State_in_US\"\n",
    "\n",
    "            # For LOC and GPE labels (i.e. locations and geopolitical entities), if one entity is a country, store it\n",
    "            if label in {\"COU\"}:\n",
    "                country = get_country_from_text(text)\n",
    "                if isinstance(country, str):\n",
    "                    countries.append(country)\n",
    "\n",
    "    # If only one country found, return it\n",
    "    if len(countries) == 1:\n",
    "        return countries[0], \"Direct_country\"\n",
    "    # If several countries found, return the most common\n",
    "    elif len(countries) > 1:\n",
    "        # Return most common\n",
    "        try:\n",
    "            return Counter(countries).most_common(1)[0][0], \"Most_common_list_countries\"\n",
    "        except:\n",
    "            with open(DF_input + \"logs errors Most common list countries.txt\", \"a\") as f:\n",
    "                f.write(str(cell_content) + \", \" + str(countries) + \"\\n\")\n",
    "                \n",
    "        \n",
    "    # No matches from COU, try INS matching to scientific institutions DF\n",
    "    entity_text = \" \".join(text_blob)\n",
    "    for el in reversed(parsed_content):\n",
    "        if el.get(\"entity_group\") == \"INS\":\n",
    "            name = el[\"word\"].strip(\".\")\n",
    "\n",
    "            # Direct match\n",
    "            if name in institution_to_country:\n",
    "                return get_country_from_text(institution_to_country[name]), \"Direct_institution\"\n",
    "\n",
    "            # Fallback regex search\n",
    "            matches = [inst for inst, pattern in compiled_institution_patterns if pattern.search(name)]\n",
    "            if len(matches) == 1:\n",
    "                return get_country_from_text(institution_to_country[matches[0]]), \"Regex_institution\"\n",
    "\n",
    "    # Try entity database\n",
    "    for el in reversed(parsed_content):\n",
    "        name = el.get(\"word\", \"\").strip(\".\")\n",
    "        if name in entity_to_country:\n",
    "            country_code = entity_to_country[name]\n",
    "            country = get_country_from_text(country_code)\n",
    "            if country and re.search(r'\\b' + re.escape(country) + r'\\b', entity_text):\n",
    "                return country, \"Entity_database\"\n",
    "\n",
    "    # If all else fails, try calls to location APIs\n",
    "    # Some calls to Nominatim will be done by passing all text collected by NER. This needs to be prepared\n",
    "    # Merge all texts into one string, in case needed for passing to code below\n",
    "    string_parts = [el[\"word\"] for el in parsed_content if isinstance(el, dict) and \"word\" in el]\n",
    "    string = \", \".join(string_parts) + \", \" if string_parts else \"\"\n",
    "    all_text = string[:-2] # Remove last \" ,\"\n",
    "    \n",
    "    # Prepare for submitting to Nominatim\n",
    "    all_text_submit = quote_plus(all_text)\n",
    "    \n",
    "    \n",
    "    # Other calls will use just the last ORG-labelled text (corresponding to the Institution). This needs to be prepared\n",
    "    if len(parsed_content_ins) > 0:\n",
    "        last_org = parsed_content_ins[-1]\n",
    "    else:\n",
    "        last_org = \"\"\n",
    "\n",
    "    if isinstance(last_org, str):\n",
    "        last_org_submit = quote_plus(last_org)\n",
    "    else:\n",
    "        last_org_submit = \"\"\n",
    "    \n",
    "    # Call Nominatim with the institution only (last ORG colledted by NER)\n",
    "    result = requests.get(\"https://nominatim.openstreetmap.org/search?q=\"+last_org_submit+\"&format=json&addressdetails=1\", headers=headers)\n",
    "    if result.status_code == 200:\n",
    "        content = json.loads(result.content)\n",
    "    \n",
    "        # If Nominatim retrieves only one item, return its corresponding country\n",
    "        if len(content) == 1:\n",
    "            candidate = content[0][\"address\"][\"country_code\"]\n",
    "            return get_country_from_text(candidate), \"Nominatim\"\n",
    "    \n",
    "        # Otherwise, try with the whole affiliation in Nominatim\n",
    "        else:\n",
    "            time.sleep(1)\n",
    "            result_all = requests.get(\n",
    "                \"https://nominatim.openstreetmap.org/search?q=\" + all_text_submit + \"&format=json&addressdetails=1\", \n",
    "                headers=headers\n",
    "            )\n",
    "            try:\n",
    "                if result_all.content:\n",
    "                    content_all = result_all.json()\n",
    "                else:\n",
    "                    content_all = []\n",
    "            except json.JSONDecodeError:\n",
    "                content_all = []\n",
    "    \n",
    "            # Again, if Nominatim retrieves only one item, return its corresponding country\n",
    "            if len(content_all) == 1:\n",
    "                if \"address\" in content_all[0].keys() and \"country_code\" in content_all[0][\"address\"]:\n",
    "                    candidate = content_all[0][\"address\"][\"country_code\"]\n",
    "                    return get_country_from_text(candidate), \"Nominatim\"\n",
    "       \n",
    "    return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "47b9a7d3-bf77-4bc3-b4db-2829149332d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Break dataset in 4 parts and iterate over them to get the Country data to avoid losing all information if failure happens\n",
    "list_df_to_fix = []\n",
    "\n",
    "list_df_to_fix.append(df_to_fix.iloc[:31000])\n",
    "list_df_to_fix.append(df_to_fix.iloc[31000:62000])\n",
    "list_df_to_fix.append(df_to_fix.iloc[62000:93000])\n",
    "list_df_to_fix.append(df_to_fix.iloc[93000:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "dc95bb4c-de8c-44d2-a7eb-3827794c3479",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing csv to fix\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 31000/31000 [16:44:26<00:00,  1.94s/it]\n",
      "C:\\Users\\svalb\\AppData\\Local\\Temp\\ipykernel_4356\\3258416539.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp_df[[\"Country\", \"Country_source\"]] = temp_df[\"NER_BERT\"].progress_apply(extract_country_with_states).apply(pd.Series)\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 31000/31000 [13:01:18<00:00,  1.51s/it]\n",
      "C:\\Users\\svalb\\AppData\\Local\\Temp\\ipykernel_4356\\3258416539.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp_df[[\"Country\", \"Country_source\"]] = temp_df[\"NER_BERT\"].progress_apply(extract_country_with_states).apply(pd.Series)\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 28561/28561 [12:16:28<00:00,  1.55s/it]\n",
      "C:\\Users\\svalb\\AppData\\Local\\Temp\\ipykernel_4356\\3258416539.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp_df[[\"Country\", \"Country_source\"]] = temp_df[\"NER_BERT\"].progress_apply(extract_country_with_states).apply(pd.Series)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Parsing time: 151346.5\n",
      "Parsing finished\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "tqdm.pandas()\n",
    "print(f\"Parsing csv to fix\")\n",
    "for el in [1,2,3]:\n",
    "    temp_df = list_df_to_fix[el]\n",
    "    temp_df[[\"Country\", \"Country_source\"]] = temp_df[\"NER_BERT\"].progress_apply(extract_country_with_states).apply(pd.Series)\n",
    "    temp_df.to_csv(DF_isna_input + 'fixed_with_NER_BERT_' + str(el) +'.csv', index=False)\n",
    "print(f\"--Parsing time: {str(round(time.time()-start, 2))}\")\n",
    "print(\"Parsing finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "81ba7bef-5816-43d5-b4e3-2e3e656aed43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "121561"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_to_fix.loc[df_to_fix['Country'].isna()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "96eb23e9-81a9-46d3-a969-6362930b14f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[{'entity_group': 'INS', 'score': np.float32(0.9998581), 'word': 'Wayne State University', 'start': 0, 'end': 22}, {'entity_group': 'INS', 'score': np.float32(0.9997116), 'word': 'Presbyterian Healthcare Services', 'start': 54, 'end': 86}, {'entity_group': 'INS', 'score': np.float32(0.9994793), 'word': 'Ascension Hospital', 'start': 88, 'end': 106}, {'entity_group': 'INS', 'score': np.float32(0.999459), 'word': 'Sichuan University', 'start': 139, 'end': 157}, {'entity_group': 'COU', 'score': np.float32(0.9989292), 'word': 'China', 'start': 159, 'end': 164}]\""
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_to_fix.iloc[6][\"NER_BERT\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "48c72ff6-141e-4801-8fcd-75ca85181f51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'entity_group': 'INS',\n",
       "  'score': 0.9998581,\n",
       "  'word': 'Wayne State University',\n",
       "  'start': 0,\n",
       "  'end': 22},\n",
       " {'entity_group': 'INS',\n",
       "  'score': 0.9997116,\n",
       "  'word': 'Presbyterian Healthcare Services',\n",
       "  'start': 54,\n",
       "  'end': 86},\n",
       " {'entity_group': 'INS',\n",
       "  'score': 0.9994793,\n",
       "  'word': 'Ascension Hospital',\n",
       "  'start': 88,\n",
       "  'end': 106},\n",
       " {'entity_group': 'INS',\n",
       "  'score': 0.999459,\n",
       "  'word': 'Sichuan University',\n",
       "  'start': 139,\n",
       "  'end': 157},\n",
       " {'entity_group': 'COU',\n",
       "  'score': 0.9989292,\n",
       "  'word': 'China',\n",
       "  'start': 159,\n",
       "  'end': 164}]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cell_content = df_to_fix.iloc[6][\"NER_BERT\"]\n",
    "cell_content = re.sub(r'np\\.float32\\(([^)]+)\\)', r'\\1', cell_content)\n",
    "        \n",
    "parsed_content = ast.literal_eval(cell_content)\n",
    "# Make a separate variable for the organizations\n",
    "parsed_content_ins = [ins for ins in parsed_content if ins[\"entity_group\"] == \"INS\"]\n",
    "\n",
    "parsed_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "4cb176c3-c5aa-48dc-9bf9-32725d710e90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'entity_group': 'INS',\n",
       "  'score': 0.9998581,\n",
       "  'word': 'Wayne State University',\n",
       "  'start': 0,\n",
       "  'end': 22},\n",
       " {'entity_group': 'INS',\n",
       "  'score': 0.9997116,\n",
       "  'word': 'Presbyterian Healthcare Services',\n",
       "  'start': 54,\n",
       "  'end': 86},\n",
       " {'entity_group': 'INS',\n",
       "  'score': 0.9994793,\n",
       "  'word': 'Ascension Hospital',\n",
       "  'start': 88,\n",
       "  'end': 106},\n",
       " {'entity_group': 'INS',\n",
       "  'score': 0.999459,\n",
       "  'word': 'Sichuan University',\n",
       "  'start': 139,\n",
       "  'end': 157}]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed_content_ins"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
