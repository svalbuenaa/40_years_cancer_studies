{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ef54bae-c419-4666-b029-246b42b8b898",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import gc\n",
    "import time\n",
    "import re\n",
    "import ast\n",
    "import country_converter as coco\n",
    "import time\n",
    "import requests\n",
    "import json\n",
    "import googlemaps\n",
    "from urllib.parse import quote_plus\n",
    "from collections import Counter\n",
    "from functools import lru_cache\n",
    "\n",
    "# Manage API Keys\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "api_key_GOOGLEMAPS = os.getenv(\"API_KEY_GoogleMaps_geocoding_new\")\n",
    "user_agent_NOMINATIM = os.getenv(\"USER_AGENT_NOMINATIM\")\n",
    "\n",
    "import logging\n",
    "coco_logger = logging.getLogger('country_converter.country_converter')\n",
    "coco_logger.setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "619c3c9d-1578-4823-84a5-a09824e8f437",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " C:\\Users\\svalb\\OneDrive\\Escritorio\\Data_40_years_cancer_studies\\parsedXMLs_update_2025-09\\\n"
     ]
    }
   ],
   "source": [
    "# Path to the .csv files with articles' information\n",
    "DF_input = input().strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1bafe16a-ebab-4883-b3ee-1ae6423779d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " C:\\Users\\svalb\\OneDrive\\Escritorio\\Data_40_years_cancer_studies\\resources\\allCountries_clean.csv\n"
     ]
    }
   ],
   "source": [
    "# Path to the .csv file with geographical entities information \n",
    "entities_database_input = input().strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "458742f3-0efa-4b0a-bb61-de1d55664d9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " C:\\Users\\svalb\\OneDrive\\Escritorio\\Data_40_years_cancer_studies\\resources\\ScimagoIR 2025 - Overall Rank.csv\n"
     ]
    }
   ],
   "source": [
    "# Path to the .csv file with scientific institutions information\n",
    "institutions_database_input = input().strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88e15d09-8e59-4641-94bc-7e24de50f8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import databases\n",
    "entities_database = pd.read_csv(entities_database_input)\n",
    "institutions_database = pd.read_csv(institutions_database_input, sep=\";\")\n",
    "\n",
    "# Remove \" *\" from institutions when present\n",
    "institutions_database[\"Institution\"] = institutions_database[\"Institution\"].apply(lambda x: x[:-2] if x[-2:] == \" *\" else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e502e711-27ec-40c4-9386-41acdd2a9273",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import list of csvs to parse\n",
    "list_csvs = []\n",
    "\n",
    "for file in os.listdir(DF_input):\n",
    "    if file[-4:] == \".csv\":\n",
    "        list_csvs.append(file)\n",
    "\n",
    "n_csvs = len(list_csvs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3cd3c98f-f85a-426c-88e6-e6f38940b117",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a dictionary for US states. \n",
    "# Many article's affiliation have the state name/ code and not \"United States\"\n",
    "us_states = [\n",
    "    \"Alabama\", \"AL\", \"Al\",\n",
    "    \"Alaska\", \"AK\", \"Ak\",\n",
    "    \"Arizona\", \"AZ\", \"Az\",\n",
    "    \"Arkansas\", \"AR\", \"Ar\",\n",
    "    \"California\", \"CA\", \"Ca\",\n",
    "    \"Colorado\", \"CO\", \"Co\",\n",
    "    \"Connecticut\", \"CT\", \"Ct\",\n",
    "    \"Delaware\", \"DE\", \"De\",\n",
    "    \"Florida\", \"FL\", \"Fl\",\n",
    "    \"Georgia\", \"GA\", \"Ga\",\n",
    "    \"Hawaii\", \"HI\", \"Hi\",\n",
    "    \"Idaho\", \"ID\", \"Id\",\n",
    "    \"Illinois\", \"IL\", \"Il\",\n",
    "    \"Indiana\", \"IN\", \"In\",\n",
    "    \"Iowa\", \"IA\", \"Ia\",\n",
    "    \"Kansas\", \"KS\", \"Ks\",\n",
    "    \"Kentucky\", \"KY\", \"Ky\",\n",
    "    \"Louisiana\", \"LA\", \"La\",\n",
    "    \"Maine\", \"ME\", \"Me\",\n",
    "    \"Maryland\", \"MD\", \"Md\",\n",
    "    \"Massachusetts\", \"MA\", \"Ma\",\n",
    "    \"Michigan\", \"MI\", \"Mi\",\n",
    "    \"Minnesota\", \"MN\", \"Mn\",\n",
    "    \"Mississippi\", \"MS\", \"Ms\",\n",
    "    \"Missouri\", \"MO\", \"Mo\",\n",
    "    \"Montana\", \"MT\", \"Mt\",\n",
    "    \"Nebraska\", \"NE\", \"Ne\",\n",
    "    \"Nevada\", \"NV\", \"Nv\",\n",
    "    \"New Hampshire\", \"NH\", \"Nh\",\n",
    "    \"New Jersey\", \"NJ\", \"Nj\",\n",
    "    \"New Mexico\", \"NM\", \"Nm\",\n",
    "    \"New York\", \"NY\", \"Ny\",\n",
    "    \"North Carolina\", \"NC\", \"Nc\",\n",
    "    \"North Dakota\", \"ND\", \"Nd\",\n",
    "    \"Ohio\", \"OH\", \"Oh\",\n",
    "    \"Oklahoma\", \"OK\", \"Ok\",\n",
    "    \"Oregon\", \"OR\", \"Or\",\n",
    "    \"Pennsylvania\", \"PA\", \"Pa\",\n",
    "    \"Rhode Island\", \"RI\", \"Ri\",\n",
    "    \"South Carolina\", \"SC\", \"Sc\",\n",
    "    \"South Dakota\", \"SD\", \"Sd\",\n",
    "    \"Tennessee\", \"TN\", \"Tn\",\n",
    "    \"Texas\", \"TX\", \"Tx\",\n",
    "    \"Utah\", \"UT\", \"Ut\",\n",
    "    \"Vermont\", \"VT\", \"Vt\",\n",
    "    \"Virginia\", \"VA\", \"Va\",\n",
    "    \"Washington\", \"WA\", \"Wa\",\n",
    "    \"West Virginia\", \"WV\", \"Wv\",\n",
    "    \"Wisconsin\", \"WI\", \"Wi\",\n",
    "    \"Wyoming\", \"WY\", \"Wy\",\n",
    "    \"District of Columbia\", \"DC\", \"Dc\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dfffffae-610b-4ee3-8e32-a1290f4ae290",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precompute lookup tables\n",
    "institution_to_country = dict(zip(institutions_database[\"Institution\"], institutions_database[\"Country\"]))\n",
    "entity_to_country = dict(zip(entities_database[\"name\"], entities_database[\"country code\"]))\n",
    "all_institutions_set = set(institution_to_country.keys())\n",
    "\n",
    "# Instance conerter\n",
    "cc = coco.CountryConverter()\n",
    "\n",
    "# MUST include contact info. Example format: 'Application_name/1.0 (yourEmail@provider.com)'\n",
    "headers = {\n",
    "    'User-Agent': user_agent_NOMINATIM  \n",
    "}\n",
    "\n",
    "# Instantiate the gmaps client\n",
    "gmaps = googlemaps.Client(key=api_key_GOOGLEMAPS)\n",
    "\n",
    "# Compiled regex list if regex matching is required\n",
    "compiled_institution_patterns = [(inst, re.compile(re.escape(inst))) for inst in institution_to_country]\n",
    "\n",
    "@lru_cache(maxsize=1000)\n",
    "def get_country_from_text(text):\n",
    "    \"\"\"Fast country name conversion with cache.\"\"\"\n",
    "    try:\n",
    "        # Attempt to extract country directly from text passed to the function (NER)\n",
    "        result = cc.convert(names=text, to='name_short')\n",
    "        return result if result != \"not found\" else None\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def extract_country_with_states(cell_content):\n",
    "    # If NER extracted nothing, return None\n",
    "    if pd.isna(cell_content):\n",
    "        return None, None\n",
    "\n",
    "    try:\n",
    "        # Try to convert the content in the NER field to list\n",
    "        parsed_content = ast.literal_eval(cell_content)\n",
    "        # Make a separate variable for the organizations\n",
    "        parsed_content_org = [org for org in parsed_content if org[\"label\"] == \"ORG\"]\n",
    "    except:\n",
    "        return None, None\n",
    "\n",
    "    # If output is not a list, return None\n",
    "    if not isinstance(parsed_content, list):\n",
    "        return None, None\n",
    "\n",
    "    countries = []\n",
    "    text_blob = []\n",
    "\n",
    "    # NER field should contain several dictionaries (one per entity found by NER)\n",
    "    for el in parsed_content:\n",
    "        if isinstance(el, dict):\n",
    "            # Separate text and label (ORG, LOC, etc.)\n",
    "            text = el.get(\"text\", \"\").strip(\".\") # Remove points as trailing spaces after/before texts\n",
    "            label = el.get(\"label\", \"\")\n",
    "\n",
    "            # At some point passing the whole string to an API might be needed, so they are prepared\n",
    "            text_blob.append(text)\n",
    "\n",
    "            # Check if any named entity corresponds to a US state. If so, return United States\n",
    "            if text in us_states:\n",
    "                return \"United States\", \"State_in_US\"\n",
    "\n",
    "            # For LOC and GPE labels (i.e. locations and geopolitical entities), if one entity is a country, store it\n",
    "            if label in {\"LOC\", \"GPE\"}:\n",
    "                country = get_country_from_text(text)\n",
    "                if isinstance(country, str):\n",
    "                    countries.append(country)\n",
    "\n",
    "    # If only one country found, return it\n",
    "    if len(countries) == 1:\n",
    "        return countries[0], \"Direct_country\"\n",
    "    # If several countries found, return the most common\n",
    "    elif len(countries) > 1:\n",
    "        # Return most common\n",
    "        try:\n",
    "            return Counter(countries).most_common(1)[0][0], \"Most_common_list_countries\"\n",
    "        except:\n",
    "            with open(DF_input + \"logs errors Most common list countries.txt\", \"a\") as f:\n",
    "                f.write(str(cell_content) + \", \" + str(countries) + \"\\n\")\n",
    "                \n",
    "        \n",
    "    # No matches from LOC/GPE, try ORG matching to scientific institutions DF\n",
    "    entity_text = \" \".join(text_blob)\n",
    "    for el in reversed(parsed_content):\n",
    "        if el.get(\"label\") == \"ORG\":\n",
    "            name = el[\"text\"].strip(\".\")\n",
    "\n",
    "            # Direct match\n",
    "            if name in institution_to_country:\n",
    "                return get_country_from_text(institution_to_country[name]), \"Direct_institution\"\n",
    "\n",
    "            # Fallback regex search\n",
    "            matches = [inst for inst, pattern in compiled_institution_patterns if pattern.search(name)]\n",
    "            if len(matches) == 1:\n",
    "                return get_country_from_text(institution_to_country[matches[0]]), \"Regex_institution\"\n",
    "\n",
    "    # Try entity database\n",
    "    for el in reversed(parsed_content):\n",
    "        name = el.get(\"text\", \"\").strip(\".\")\n",
    "        if name in entity_to_country:\n",
    "            country_code = entity_to_country[name]\n",
    "            country = get_country_from_text(country_code)\n",
    "            if country and re.search(r'\\b' + re.escape(country) + r'\\b', entity_text):\n",
    "                return country, \"Entity_database\"\n",
    "\n",
    "    # If all else fails, try calls to location APIs\n",
    "    # Some calls to Nominatim and Google Maps will be done by passing all text collected by NER. This needs to be prepared\n",
    "    # Merge all texts into one string, in case needed for passing to code below\n",
    "    string_parts = [el[\"text\"] for el in parsed_content if isinstance(el, dict) and \"text\" in el]\n",
    "    string = \", \".join(string_parts) + \", \" if string_parts else \"\"\n",
    "    all_text = string[:-2] # Remove last \" ,\"\n",
    "    \n",
    "    # Prepare for submitting to Nominatim\n",
    "    all_text_submit = quote_plus(all_text)\n",
    "    \n",
    "    \n",
    "    # Other calls will use just the last ORG-labelled text (corresponding to the Institution). This needs to be prepared\n",
    "    if len(parsed_content_org) > 0:\n",
    "        last_org = parsed_content_org[-1]\n",
    "    else:\n",
    "        last_org = \"\"\n",
    "\n",
    "    if isinstance(last_org, str):\n",
    "        last_org_submit = quote_plus(last_org)\n",
    "    else:\n",
    "        last_org_submit = \"\"\n",
    "    \n",
    "    # Call Nominatim with the institution only (last ORG colledted by NER)\n",
    "    result = requests.get(\"https://nominatim.openstreetmap.org/search?q=\"+last_org_submit+\"&format=json&addressdetails=1\", headers=headers)\n",
    "    if result.status_code == 200:\n",
    "        content = json.loads(result.content)\n",
    "    \n",
    "        # If Nominatim retrieves only one item, return its corresponding country\n",
    "        if len(content) == 1:\n",
    "            candidate = content[0][\"address\"][\"country_code\"]\n",
    "            return get_country_from_text(candidate), \"Nominatim\"\n",
    "    \n",
    "        # Otherwise, try with the whole affiliation in Nominatim\n",
    "        else:\n",
    "            time.sleep(1)\n",
    "            result_all = requests.get(\n",
    "                \"https://nominatim.openstreetmap.org/search?q=\" + all_text_submit + \"&format=json&addressdetails=1\", \n",
    "                headers=headers\n",
    "            )\n",
    "            try:\n",
    "                if result_all.content:\n",
    "                    content_all = result_all.json()\n",
    "                else:\n",
    "                    content_all = []\n",
    "            except json.JSONDecodeError:\n",
    "                content_all = []\n",
    "    \n",
    "            # Again, if Nominatim retrieves only one item, return its corresponding country\n",
    "            if len(content_all) == 1:\n",
    "                if \"address\" in content_all[0].keys() and \"country_code\" in content_all[0][\"address\"]:\n",
    "                    candidate = content_all[0][\"address\"][\"country_code\"]\n",
    "                    return get_country_from_text(candidate), \"Nominatim\"\n",
    "    \n",
    "            # Otherwise, try with Google Maps\n",
    "            else:\n",
    "                try:\n",
    "                    # First, try with the whole affiliation\n",
    "                    geocode_result = gmaps.geocode(all_text)\n",
    "                    if geocode_result:\n",
    "                        candidate = [component[\"short_name\"] for component in geocode_result[0][\"address_components\"] if \"country\" in component[\"types\"]]\n",
    "                        # If Google Maps call retrieves only one item, return its associated country \n",
    "                        if len(candidate) == 1:\n",
    "                            return get_country_from_text(candidate[0]), \"Google Maps\"\n",
    "                    \n",
    "                    # Otherwise, try Google Maps only with the last ORG item of the affiliation (institution)\n",
    "                    else:\n",
    "                        try:\n",
    "                            geocode_result = gmapsgeocode(text)\n",
    "                            if geocode_result:\n",
    "                                candidate = [component[\"short_name\"] for component in geocode_result[0][\"address_components\"] if \"country\" in component[\"types\"]]\n",
    "                                # Again, if Google Maps call retrieves only one item, return its associated country \n",
    "                                if len(candidate) == 1:\n",
    "                                    return get_country_from_text(candidate[0]), \"Google Maps\"\n",
    "    \n",
    "                # If all fails, return None\n",
    "                            else:\n",
    "                                return None, None\n",
    "                        except:\n",
    "                            return None, None\n",
    "                except:\n",
    "                    return None, None\n",
    "    \n",
    "    return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "367a5d5e-5b05-4087-babd-72859c7ba5f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed_csvs = []\n",
    "with open(DF_input + \"csv files with Country.txt\", \"r\") as f:\n",
    "    for csv in f:\n",
    "        parsed_csvs.append(csv[:-1])\n",
    "\n",
    "parsed_csvs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a67a5598-ed82-409c-9546-cf76e8338a08",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\svalb\\AppData\\Local\\Temp\\ipykernel_9180\\2290455495.py:3: DtypeWarning: Columns (2,3,4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(DF_input + csv)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing csv: parsedXMLs_update_2025__09_33200.csv (1/1)\n",
      "--Parsing time: 2650.94\n",
      "Parsing finished\n"
     ]
    }
   ],
   "source": [
    "for csv in list_csvs:\n",
    "    if csv not in parsed_csvs:\n",
    "        df = pd.read_csv(DF_input + csv)\n",
    "        start = time.time()\n",
    "        print(f\"Parsing csv: {csv} ({str(list_csvs.index(csv) + 1)}/{str(n_csvs)})\")\n",
    "        df[[\"Country\", \"Country_source\"]] = df[\"NER_lastAuthor\"].apply(extract_country_with_states).apply(pd.Series)\n",
    "        df.to_csv(DF_input + csv, index=False)\n",
    "        with open(DF_input + \"csv files with Country.txt\", \"a\") as f:\n",
    "            f.write(csv+\"\\n\")\n",
    "        print(f\"--Parsing time: {str(round(time.time()-start, 2))}\")\n",
    "        del df\n",
    "print(\"Parsing finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02316fe8-53e6-40e1-97a4-ea3ac2fc8788",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
